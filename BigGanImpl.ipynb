{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Pytorch and Torchvision Imports\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.optim import Adam\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "# Torchgan Imports\n",
    "import torchgan\n",
    "from torchgan.layers import SpectralNorm2d, SelfAttention2d\n",
    "from torchgan.models import Generator, Discriminator\n",
    "from torchgan.losses import WassersteinGeneratorLoss, WassersteinDiscriminatorLoss, WassersteinGradientPenalty\n",
    "from torchgan.trainer import Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n",
      "Epochs: 20\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    # Use deterministic cudnn algorithms\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    epochs = 20\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    epochs = 10\n",
    "\n",
    "print(\"Device: {}\".format(device))\n",
    "print(\"Epochs: {}\".format(epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResUp(nn.Module):\n",
    "    def __init__(self, step_channels=64):\n",
    "        d = step_channels\n",
    "        self.skip = nn.Sequential(\n",
    "                      nn.Upsample(),\n",
    "                      nn.Conv2d(d * 2, d * 4, 1))\n",
    "        self.model = nn.Sequential(\n",
    "                    nn.BatchNorm2d(d), nn.LeakyReLU(0.2),\n",
    "                    nn.Upsample(),\n",
    "                    nn.Conv2d(d * 2, d * 4, 3),\n",
    "                    nn.BatchNorm2d(d * 2), nn.LeakyReLU(0.2),\n",
    "                    nn.Conv2d(d * 2, d * 4, 3))\n",
    "    def forward(self, x):\n",
    "        main = self.model(x)\n",
    "        skip = self.skip(x)\n",
    "        out = torch.add(main, skip)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResDown(nn.Module):\n",
    "    def __init__(self, step_channels=64):\n",
    "        d = step_channels\n",
    "        self.skip = nn.Sequential(\n",
    "                      nn.Conv2d(d * 2, d * 4, 1),\n",
    "                      nn.AvgPool2d())\n",
    "        self.model = nn.Sequential(\n",
    "                    nn.LeakyReLU(0.2),\n",
    "                    nn.Conv2d(d * 2, d * 4, 3),\n",
    "                    nn.LeakyReLU(0.2),\n",
    "                    nn.Conv2d(d * 2, d * 4, 3),\n",
    "                    nn.AvgPool2d())\n",
    "    def forward(self, x):\n",
    "        main = self.model(x)\n",
    "        skip = self.skip(x)\n",
    "        out = torch.add(skip, main)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigGanGenerator(Generator):\n",
    "    def __init__(self, chn=64):\n",
    "        super(BigGanGenerator, self).__init__(100, 'none')\n",
    "        self.linear = SpectralNorm2d(nn.Linear(100,4 * 4 * 16 * chn))\n",
    "        self.conv = nn.Sequential(ResUp(16*chn, 16*chn),\n",
    "                                ResUp(16*chn, 8*chn),\n",
    "                                ResUp(8*chn, 4*chn),\n",
    "                                ResUp(4*chn, 2*chn),\n",
    "                                SelfAttention2d(2*chn),\n",
    "                                ResUp(2*chn, 1*chn))\n",
    "        self.last = nn.Sequential(nn.BatchNorm2d(d), nn.LeakyReLU(0.2),\n",
    "                nn.Conv2d(d * 2, 3, 3), nn.Tanh())\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        out = self.conv(out)\n",
    "        out = self.last(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigGanDiscriminator(Discriminator):\n",
    "    def __init__(self, chn=64):\n",
    "#         chn = step_channels\n",
    "        super(BigGanDiscriminator, self).__init__(3, 'none')\n",
    "        self.pre_conv = nn.Sequential(SpectralNorm(nn.Conv2d(3, 1*chn, 3,padding=1),),\n",
    "                                      nn.ReLU(),\n",
    "                                      SpectralNorm(nn.Conv2d(1*chn, 1*chn, 3,padding=1),),\n",
    "                                      nn.AvgPool2d(2))\n",
    "        self.pre_skip = SpectralNorm(nn.Conv2d(3, 1*chn, 1))\n",
    "\n",
    "        self.conv = nn.Sequential(ResDown(1*chn, 1*chn),\n",
    "                                  SelfAttention2d(64*64),\n",
    "                                  ResDown(1*chn, 2*chn),    \n",
    "                                  ResDown(2*chn, 4*chn),\n",
    "                                  ResDown(4*chn, 8*chn),\n",
    "                                  ResDown(8*chn, 16*chn))\n",
    "        self.res_layer = ResidualBlock2d(16*chn, 16*chn)\n",
    "        self.linear = SpectralNorm2d(nn.Linear(4 * 4 * 16 * chn))\n",
    "        self.last = nn.LeakyReLU(0.2)\n",
    "    def forward(self, x):\n",
    "        out = self.pre_conv(x)\n",
    "        out = self.pre_skip(out)\n",
    "        out = self.conv(out)\n",
    "        out = self.res_layer(out)\n",
    "        out = self.linear(out)\n",
    "        out = self.last(out)\n",
    "        out = out.sum(2)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_params = {\n",
    "    \"generator\": {\"name\": BigGanGenerator, \"args\": {\"chn\": 32},\n",
    "                  \"optimizer\": {\"name\": Adam, \"args\": {\"lr\": 0.0001, \"betas\": (0.0, 0.999)}}},\n",
    "    \"discriminator\": {\"name\": BigGanDiscriminator, \"args\": {\"chn\": 32},\n",
    "                      \"optimizer\": {\"name\": Adam, \"args\": {\"lr\": 0.0004, \"betas\": (0.0, 0.999)}}}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(network_params, [MinimaxGeneratorLoss(), MinimaxDiscriminatorLoss()], sample_size=64, epochs=epochs, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
